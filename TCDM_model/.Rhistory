{
climatelayers_ss[[i]] <- (climatelayers_ss[[i]] - cellStats(climatelayers_ss[[i]], 'mean')) / cellStats(climatelayers_ss[[i]], 'sd')
}
head(climatelayers)
install.packages("terra")
install.packages("terra")
install.packages("geodata")
install.packages("corrplot")
install.packages("corrplot")
library("corrplot")
install.packages("ggplot2")
install.packages("mosaic")
install.packages("corrplot")
install.packages("corrplot")
install.packages("corrplot")
install.packages("corrplot")
6*(1/2)^5
pnorm(.8, .5, sqrt(.25/5), lower.tail = FALSE)
.224/sqrt(35/87 * (1 - 35/87) * (1/43 + 1/44))
138 + 169
307/(11034 + 11037)
-.003/sqrt(0.01390966 * (1 - 0.01390966) * (1/11034 + 1/11037))
2 * pnorm(-1.902767)
knitr::opts_chunk$set(echo = TRUE)
treatment = c(rep(0, 169), rep(1, 11037 - 169))
placebo = c(rep(0, 138), rep(1, 11034 - 138))
data = c(treatment, placebo)
treatment_identifier = c(rep(0, 11034), rep(1, 11037))
diffs = numeric(10000)
for(i in 1:10000) {
shuffle_i = sample(treatment_identifier)
diffs[i] = mean(data[shuffle_i == 0])-mean(data[shuffle_i == 1])
}
mean(abs(diffs) >= 0.003)
11037-169
11034-138
169/11037
138/11034
-.003/sqrt(0.01531213 * (1 - 0.01531213)/11037 + 0.0125068 * (1 - 0.0125068)/11034)
x = matrix(1:1000, nrow = 10)
t(x)
x $*$ t(x)
x %*% t(x)
eigen(x %*% t(x))
eigen(x %*% t(x))$values
eigen(x[,1:10] %*% t(x[,1:10]))$values
x[1:10]
x[,1:10]
x = matrix(1:100, nrow = 4)
eigen(x %*% t(x))$value
knitr::opts_chunk$set(echo = TRUE)
x = matrix(1:10, nrow = 2)
x[,1:2]
x
eigen(x%*%t(x))
eigen(x%*%t(x))$vectors
U = eigen(x%*%t(x))$vectors
U %*% t(U)
x = matrix(1:100, nrow = 20)
U $*$ t(U)
U %*% t(U)
x = matrix(1:100, nrow = 20)
U = eigen(x%*%t(x))$vectors
U %*% t(U)
x = matrix(1:100, nrow = 10)
x = matrix(1:100, nrow = 10)
U = eigen(x%*%t(x))$vectors
U %*% t(U)
eigen(U %*% t(U))
eigen(U %*% matrix(c(1, rep(0, 9), 0, 1, rep(0, 8), rep(0, 80)), nrow = 10) %*% t(U))
U %*% matrix(c(1, rep(0, 9), 0, 1, rep(0, 8), rep(0, 80)), nrow = 10) %*% t(U)
U %*% matrix(c(1, rep(0, 9), 0, 1, rep(0, 8), rep(0, 80)), nrow = 10) %*% t(U)
U[,1:2] %*% t(U[,1:2])
U[,1:2] %*% t(U[,1:2]) == U %*% matrix(c(1, rep(0, 9), 0, 1, rep(0, 8), rep(0, 80)), nrow = 10) %*% t(U)
eigen(U)
knitr::opts_chunk$set(echo = TRUE)
avg_poor = rep(0, 1601 + 2116)
not_poor = rep(1, 2318 + 136)
t.test(c(avg_poor, not_poor))
avg_poor = rep(0, 1601 + 2116)
not_poor = rep(1, 2318 + 136)
treatment = c(avg_poor, not_poor)
avg_poor_control = rep(0, 1665 + 2983)
not_poor_control = rep(1, 1186 + 92)
control = c(avg_poor_control, not_poor_control)
outcomes = c(treatment, control)
labels = c(rep(1, length(treatment)), rep(0, length(control)))
t.test(outcome ~ label)
avg_poor = rep(0, 1601 + 2116)
not_poor = rep(1, 2318 + 136)
treatment = c(avg_poor, not_poor)
avg_poor_control = rep(0, 1665 + 2983)
not_poor_control = rep(1, 1186 + 92)
control = c(avg_poor_control, not_poor_control)
outcomes = c(treatment, control)
labels = c(rep(1, length(treatment)), rep(0, length(control)))
t.test(outcomes ~ label)
avg_poor = rep(0, 1601 + 2116)
not_poor = rep(1, 2318 + 136)
treatment = c(avg_poor, not_poor)
avg_poor_control = rep(0, 1665 + 2983)
not_poor_control = rep(1, 1186 + 92)
control = c(avg_poor_control, not_poor_control)
outcomes = c(treatment, control)
labels = c(rep(1, length(treatment)), rep(0, length(control)))
t.test(outcomes ~ labels)
t.test(outcomes ~ labels, alternative = "greater")
t.test(outcomes ~ labels, alternative = "lesser")
t.test(outcomes ~ labels, alternative = "less")
t.test(outcomes ~ labels, alternative = "two.sided")
t.test(treatment)
t.test(control)
R.home()
install.packages("lme4")
install.packages("lme4")
install.packages("lme4")
install.packages("magrittr")
install.packages("readr")
rtime
library(lme4)
library(readr)
library(magrittr)
testdata <- read_csv("lmm_data.csv")
install.packages("Matrix")
install.packages("Matrix")
library(installr)
install.packages("installr")
library(installr)
updateR()
install.packages("lme4")
library(lme4)
library(readr)
library(magrittr)
testdata <- read_csv("lmm_data.csv")
install.packages("Matrix")
library(lme4)
install.packages("lme4")
install.packages("magrittr")
install.packages("readr")
R.home()
knitr::opts_chunk$set(echo = TRUE)
# Obtain the 2nd and 5th item in a vector
example_nums[c(2, 5)]
example_nums = 1:10
example_nums
# Obtain the 2nd and 5th item in a vector
example_nums[c(2, 5)]
knitr::opts_chunk$set(echo = TRUE)
nums = 1:100
nums[10]
nums2 = -10:10
nums2 = -10:10
nums2[c(3, 4, 5)]
nums2[nums2 < 0]
getwd()
AgeBMI = read.table("AgeBMI.txt", header = TRUE)
head(AgeBMI)
age = AgeBMI$Age
bmi = AgeBMI$BMI
mean(bmi)
age = AgeBMI$Age
bmi = AgeBMI$bmi
mean(bmi)
bmi_under_29 = bmi < 29
table(bmi_under_29)
knitr::opts_chunk$set(echo = TRUE)
# This makes sure that the random number generator produces the same outcome each time
set.seed(123)
num_samples = 100
# The number of people who have contracted chicken pox from a single sample of 100 people where the true probability of success is 0.85.
num_contracted = rbinom(1, num_samples, prob = 0.85)
num_contracted
# Fill in the following three variables based on the information given in the question
observed = 87/num_samples
expected = .9
SE = sqrt(.9 * (1 - .9)/num_samples)
# Code for calculation of z and one sided p value
z = (observed - expected)/SE
pval = pnorm(z)
# Print p value
pval
# This makes sure that the random number generator produces the same outcome each time
set.seed(123)
num_samples = 1000
# The number of people who have contracted chicken pox from a single sample of 100 people where the true probability of success is 0.85.
num_contracted = rbinom(1, num_samples, prob = 0.85)
num_contracted
# Fill in the following three variables based on the information given in the question
observed = 856/num_samples
expected = .9
SE = sqrt(.9 * (1 - .9)/num_samples)
# Code for calculation of z and one sided p value
z = (observed - expected)/SE
pval = pnorm(z)
# Print p value
pval
num_flips = 30
num_heads = 12
p = num_heads/num_flips
se = sqrt(p * (1 - p) / num_flips)
c(p-1.96*se, p+1.96*se)
num_flips = 30
num_heads = 21
p = num_heads/num_flips
se = sqrt(p * (1 - p) / num_flips)
c(p-1.96*se, p+1.96*se)
in_conf_int = numeric(10000)
for(i in 1:10000){
num_flips = 30
num_heads = rbinom(1, 30, prob = 0.5)
p = num_heads/num_flips
se = sqrt(p * (1 - p) / num_flips)
in_conf_int[i] = 0.5 >= (p-1.96*se) & 0.5 <= (p+1.96*se)
}
mean(in_conf_int)
barplot(table(in_conf_int)/10000, main = "Confidence Interval contains 0.5")
qt(97.5, 29)
qt(0.975, 29)
qt(0.025, 29)
c(65.02 - 2.04523 * 51.42, 65.02 + 2.04523 * 51.42)
c(65.02 - 2.04523 * 51.42/sqrt(30), 65.02 + 2.04523 * 51.42/sqrt(30))
letters
letters[0]
letters[0:11]
letters[1:11]
x = letters[0:11]
x[100]
x[-1]
x[0]
help("vapply")
obj4 <- seq(2, 10, 2)
fun4a <- function(x) {
x + 2
}
fun4bc <- function(x, y = 2) {
x^y
}
vapply(obj4, fun4a, obj4[1])
vapply(obj4, fun4a)
vapply(obj4, fun4a, 2)
vapply(obj4, fun4a, 1846)
vapply(obj4, fun4bc, numeric(1))
vapply(obj4, fun4bc, 1234)
vapply(obj4, fun4bc, 1, y=3)
vapply(obj4, fun4bc, 100, y=3)
fun4bc(obj4, y = 3)
x = [1, 2, 3, 4]
x = c(1, 2, 3, 4)
length(x)
length(x) <- 2
x
length(x)
length(x) <- 5
x
View(data)
setwd("C:/Users/14842/Desktop/BBVI/TCDM_model")
load("TDCM_multilevel_data.RData")
View(data)
data$profiles
# Random Intercept + Random Slope (Independent Random Effects)
knitr::opts_chunk$set(echo = TRUE)
library(tictoc)
library(ggplot2)
library(MASS)
library(cli)
library(torch)
library(dplyr)
library(tidyr)
library(ggpubr)
library(zeallot)
# Helper Functions
sigmoid = function(x){1/(1+exp(-x))}
bernoulli_sampler = function(n, p){as.integer(runif(n) < p)}
JJ_func = function(xi){
ans = (torch_sigmoid(xi)-1/2)/(2*xi)
ans[torch_isnan(ans)] = 1/8
ans
}
torch_cholesky_R = function(M){
X = as_array(M)
if (length(dim(X)) == 2){
return(torch_tensor(t(chol(X))))
}
if (length(dim(X)) == 3){
res = torch_zeros(dim(X))
for (i in 1:dim(X)[1]){
res[i,,] = t(chol(X[i,,]))
}
return(res)
}
}
transpose = function(M){return(M$permute(c(2,1)))}
torch_vec = function(M){return((M$permute(c(2,1)))$reshape(-1))}
torch_kronecker = function(M, N){
return(torch_tensor(kronecker(as_array(M), as_array(N))))
}
torch_outer_batch = function(M, N = NULL){
# M has dimension A*B, N has dimension A*C, the outer has dimension A*B*C
# If N is not provided, then N = M
if (is.null(N)){N = M}
torch_einsum("ab,ac->abc", list(M, N))
}
intToBin = function(x, d){
if (x == 0){res = c(0)}
if (x >= 2^d){stop("x should be in [0, 2^d-1]")}
res = c()
while (x > 1){
res = c(x %% 2, res)
x = x %/% 2
}
if (x == 1){res = c(x, res)}
if (length(res) < d){res = c(rep(0, d-length(res)), res)}
return(paste(res, collapse=""))
}
E_Z_skill_to_all = function(E_Z_K, A_K){
c(N, K, indT) %<-% E_Z_K$shape
indT = log(indT, 2)
E_Z = torch_ones(N, 2^(K*indT))
for (i in 1:2^(K*indT)){
for(k in 1:K){
E_Z[,i] = E_Z[,i]*E_Z_K[,k,as.numeric(A_K[i,k])]
}
}
return(E_Z)
}
E_Z_all_to_time = function(E_Z, A_T){
indT = A_T$shape[2]
K = log(A_T$shape[1], 2)/indT
N = E_Z$shape[1]
E_Z_T = torch_zeros(N, indT, 2^K)
for (t in 1:indT){
for (k in 1:(2^K)){
E_Z_T[,t,k] = E_Z[,A_T[,t] == k]$sum(2)
}
}
return(E_Z_T)
}
E_Z_all_to_skill = function(E_Z, A_K){
K = A_K$shape[2]
indT = log(A_K$shape[1], 2)/K
N = E_Z$shape[1]
E_Z_T = torch_zeros(N, K, 2^indT)
for (k in 1:K){
for (p in 1:(2^indT)){
E_Z_T[,k,p] = E_Z[,A_K[,k] == p]$sum(2)
}
}
return(E_Z_T)
}
generate_beta = function(d){
if (d == 2){
beta = c(-2.5, 4.5)
}else if (d == 4){
beta = c(-2.5, 2, 2, 1)
}else if (d == 8){
beta = c(-2.5, 1, 1, 0.8, 1, 0.8, 0.8, 0.5)
}else{
stop("Invalid d")
}
beta
}
generate_delta_matrix = function(Q, K){
calculate_q = function(t, q){prod(sapply(1:length(q), function(i){ifelse(substr(t,i,i) == '1', q[i], 1)}))}
calculate_delta = function(q){
t = sapply(0:(2^K-1), function(i){intToBin(i, d = K)})
Q_res = matrix(rep(sapply(t, function(x){calculate_q(x, q)}), 2^K), ncol = 2^K, byrow = T, dimnames = list(t,t))
A_res = matrix(unlist(lapply(t, function(y){sapply(t, function(x){calculate_q(x, sapply(1:K, function(i){as.numeric(substr(y,i,i))}))})})), ncol = 2^K, byrow = T, dimnames = list(t,t))
A_res*Q_res
}
J = nrow(Q)
delta_matrix = lapply(1:J, function(j){calculate_delta(Q[j,])})
valid_cols = lapply(1:J, function(j) names(which(colSums(delta_matrix[[j]])>0)))
# valid_cols = lapply(valid_cols, function(x){x[-1]})
for (j in 1:J){
delta_matrix[[j]] = matrix((delta_matrix[[j]][,valid_cols[[j]]]), nrow = 2^K, dimnames = c(list(rownames(delta_matrix[[1]])), list(valid_cols[[j]])))
}
return(delta_matrix)
}
array_to_tensor = function(list_of_arrays){
K = length(list_of_arrays)
indT = length(list_of_arrays[[1]])
for (k in 1:K){
for (t in 1:indT){
list_of_arrays[[k]][[t]] = torch_tensor(list_of_arrays[[k]][[t]])
if (length((dim(list_of_arrays[[k]][[t]]))) == 1){
list_of_arrays[[k]][[t]] = list_of_arrays[[k]][[t]]$unsqueeze(-1)
}
}
}
list_of_arrays
}
tensor_to_array = function(list_of_tensors){
K = length(list_of_tensors)
indT = length(list_of_tensors[[1]])
for (k in 1:K){
for (t in 1:indT){
list_of_tensors[[k]][[t]] = as_array(list_of_tensors[[k]][[t]])
}
}
list_of_tensors
}
# Input
# N_per_group: Number of respondents per group, (N is the sum of N_per_group across all groups)
# K: Number of skills
# J: Number of items
# C: Number of groups
# indT: Number of time points
# seed: Random seed
# rand_N: Whether to randomly generate the number of respondents per group
# rand_cor: Correlation between the random effects
# Output
# Y: response matrix with dim = N*indT*J
# X_ind: nested list of individual covariates matrix with dim = N*M, the outer list has length K, the inner list has length indT (then M = 1 when indT = 1)
# X_group: nested list of group covariates matrix with dim = C*D, the outer list has length K, the inner list has length indT
# group: index of group for each respondent
# Q_matrix: Q-matrix with dim = J*K
# profiles_index: index of profiles for each respondent, should be a number between 1 and 2^(K*indT)
# profiles: profiles for each respondent, multidimensional array with dim = N*K*indT
# beta: true beta, list of length K
# gamma: true transition parameters, nested list, the outer list has length K, the inner list has length indT, the dimension of gamma[[k]][[t]] is C when t = 1, and 2*C*M(including 2 sets of parameters) when t > 1
# omega: true group level parameters, nested list, the outer list has length K, the inner list has length indT, the dimension of omega[[k]][[t]] is D when t = 1, and 2*D*M(including 2 sets of parameters) when t > 1
data_generate = function(N_per_group = 20, K = 2, J = 20, C = 10, indT  = 2, seed = 1, rand_N = F, rand_cor = 0.8){
torch_manual_seed(seed = seed)
NC = if(rand_N){torch_randint(low = N_per_group, high = 1.5*N_per_group, size = C)}else{torch_full(size = C, fill = N_per_group)}
N = as.numeric(NC$sum())
# Generate Q-Matrix
Q_matrix = sapply(as_array(torch_randint(low = 1, high = 2^K, size = J)), function(x){intToBin(x, K)})
Q_matrix = unname(t(sapply(Q_matrix, function(x){sapply(1:K, function(i){as.numeric(substr(x,i,i))})})))
# Generate Delta Matrix
delta_matrix = generate_delta_matrix(Q_matrix, K)
# Generate Beta
beta = lapply(1:J, function(j) torch_tensor(generate_beta(2^sum(Q_matrix[j,]))))
# Generate Group Covariates
group = unlist(lapply(1:C, function(c){rep(c, as.numeric(NC[c]))}))
group_mat = torch_sparse_coo_tensor(torch_vstack(list(torch_arange(start = 1, end = N), torch_tensor(group)))$to(dtype = torch_int32()), torch_ones(size = N))
X_group = torch_cat(list(torch_ones(size = C)$unsqueeze(2), torch_bernoulli(torch_ones(size = C)*0.5)$unsqueeze(2), (torch_rand(size = C)*4+1)$unsqueeze(2)), dim = 2)
X_group = lapply(1:K, function(k){lapply(1:indT, function(t) X_group)})
# Generate Invididual Covariates
X_ind = torch_cat(list(torch_ones(size = N)$unsqueeze(2), torch_bernoulli(torch_ones(size = N)*0.5)$unsqueeze(2)), dim = 2)
X_ind = lapply(1:K, function(k){c(torch_ones(N), lapply(2:indT, function(t) X_ind))})
# Generate Omega
omega = lapply(1:K, function(k) c(torch_tensor(c(-1.5, 0.5, -0.1)), lapply(1:(indT-1), function(t){torch_cat(list(torch_tensor(cbind(c(-2, 0.5, -0.1), c(4, 1, -0.2)))$unsqueeze(1), torch_tensor(cbind(c(-1.5, 0.5, -0.2), c(3.5, 0.75, -0.15)))$unsqueeze(1)), dim = 1)})))
# Generate Gamma
Sigma_gamma = lapply(1:K, function(k) c(torch_tensor(0.2), lapply(1:(indT-1), function(t){torch_cat(list(torch_tensor(c(0.2, 0.4))$outer(torch_tensor(c(0.2, 0.4)))*torch_tensor(matrix(c(1, rand_cor, rand_cor, 1), 2))$unsqueeze(1), torch_tensor(c(0.1, 0.2))$outer(torch_tensor(c(0.1, 0.2)))*torch_tensor(matrix(c(1, rand_cor, rand_cor, 1), 2))$unsqueeze(1)), dim = 1)})))
generate_gamma = function(k, t){
if (t == 1){
return(X_group[[k]][[t]]$matmul(omega[[k]][[t]])+torch_randn(C)*Sigma_gamma[[k]][[t]])
}
else{
return(X_group[[k]][[t]]$matmul(omega[[k]][[t]])+torch_cat(list(distr_multivariate_normal(torch_zeros(2), Sigma_gamma[[k]][[t]][1,,])$sample(C)$unsqueeze(1), distr_multivariate_normal(torch_zeros(2), Sigma_gamma[[k]][[t]][2,,])$sample(C)$unsqueeze(1)), dim =1))
}
}
gamma = lapply(1:K, function(k) lapply(1:indT, function(t) generate_gamma(k = k, t = t)))
# Generate Profiles
A = lapply(0:(2^(K*indT)-1), function(x){torch_tensor(matrix(as.integer(strsplit(intToBin(x, K*indT), "")[[1]]), ncol = indT, byrow = T))})
A = torch_cat(lapply(A, function(x){x$unsqueeze(1)}), dim = 1)
prob_all = torch_zeros(N, 2^(K*indT))
for (i in 1:A$shape[1]){
profile = as_array(A[i,,])
prob = torch_ones(N)
for (k in 1:K){
prob = prob*((X_ind[[k]][[1]]*group_mat$matmul(gamma[[k]][[1]]))*(2*profile[k,1]-1))$sigmoid()
for (t in 2:indT){
if (profile[k,t-1] == 0){
gamma_tk = gamma[[k]][[t]][1,,]
}
else{
gamma_tk = gamma[[k]][[t]][2,,]
}
prob = prob*(((X_ind[[k]][[t]]*group_mat$matmul(gamma_tk))$sum(2)*(2*profile[k,t]-1))$sigmoid())
}
}
prob_all[,i] = prob
}
profiles_index = distr_categorical(prob_all)$sample()$squeeze() # index of profiles
profiles = A[profiles_index,,]$float() # dim = (N, K, T)
# Generate Response Matrix Y
Y = torch_zeros(N, indT, J)
for (t in 1:indT){
for(j in 1:J){
Y[,t,j] = torch_bernoulli(torch_tensor(delta_matrix[[j]][as.numeric(profiles[,,t]$matmul(torch_tensor(2^((K-1):0)))+1),])$matmul(beta[[j]])$sigmoid())
}
}
list('Y' = as_array(Y), 'X_group' = tensor_to_array(X_group), 'X_ind' = tensor_to_array(X_ind), 'group' = group, 'profiles' = as_array(profiles), 'profiles_index' = as.numeric(profiles_index), 'beta' = lapply(beta, function(x) as_array(x)), 'Q_matrix' = Q_matrix, 'omega' = tensor_to_array(omega), 'gamma' = tensor_to_array(gamma))
}
data = data_generate(N_per_group = 100, K = 2, J = 25, C = 50, indT = 2, seed = 1, rand_N = F, rand_cor = 0)
data_large_questions = data_generate(N_per_group = 100, K = 2, J = 50, C = 50, indT = 2, seed = 1, rand_N = F, rand_cor = 0)
save(data_large_questions, "TDCM_multilevel_J50_data.RData")
save(data_large_questions, file="TDCM_multilevel_J50_data.RData")
data[["Y"]]
data[["Y"]][1]
data[["Y"]][[1]]
data[["Y"]][1, 1]
data[["Y"]][1, 1, 1]
data[["Y"]][1, 2, 1]
data[["Y"]][1, 3, 1]
data[["Y"]][1, 1, 1]
data[["Y"]][1, 1, 2]
data[["Y"]][1, 1, 3]
data[["Y"]][1, 1, 4]
data[["Y"]][1, 1, 5]
data[["Y"]][1, 1, 25]
data[["Y"]][1, 1, 26]
data[["Y"]][1, 2, 1]
data[["Y"]][1, 2, 2]
data[["Y"]][1, 1, 1]
data[["Y"]][2, 1, 1]
data[["Y"]][1, 1, 25]
data[["Y"]][1, 1, 24]
data[["Y"]][1, 1, 23]
data = data_generate(N_per_group = 100, K = 2, J = 25, C = 50, indT = 3, seed = 1, rand_N = F, rand_cor = 0)
View(data)
